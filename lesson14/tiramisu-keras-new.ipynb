{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/anaconda3/envs/tf1.0_gpu/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiramisu / Camvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup for training images\n",
    "PATH = '/data/code/SegNet-Tutorial/CamVid/'\n",
    "frames_path = PATH+'train/'\n",
    "labels_path = PATH+'trainannot/'\n",
    "\n",
    "\n",
    "# fnames: file name of each training image\n",
    "fnames = glob.glob(frames_path+'*.png')\n",
    "lnames = [labels_path+os.path.basename(fn) for fn in fnames]\n",
    "img_sz = (480,360)\n",
    "\n",
    "def open_image(fn): return np.array(Image.open(fn))\n",
    "\n",
    "imgs = np.stack([open_image(fn) for fn in fnames])\n",
    "labels = np.stack([open_image(fn) for fn in lnames])\n",
    "\n",
    "imgs = imgs/255.\n",
    "\n",
    "n,r,c,ch = imgs.shape\n",
    "imgs-=0.4\n",
    "imgs/=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup for test images\n",
    "PATH = '/data/code/SegNet-Tutorial/CamVid/'\n",
    "test_frames_path = PATH+'test/'\n",
    "test_labels_path = PATH+'testannot/'\n",
    "\n",
    "\n",
    "# fnames: file name of each training image\n",
    "test_fnames = glob.glob(test_frames_path+'*.png')\n",
    "test_lnames = [test_labels_path+os.path.basename(fn) for fn in test_fnames]\n",
    "img_sz = (480,360)\n",
    "\n",
    "def open_image(fn): return np.array(Image.open(fn))\n",
    "\n",
    "test_imgs = np.stack([open_image(fn) for fn in test_fnames])\n",
    "test_labels = np.stack([open_image(fn) for fn in test_lnames])\n",
    "\n",
    "test_imgs = test_imgs/255.\n",
    "\n",
    "test_imgs-=0.4\n",
    "test_imgs/=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Generator demo\n",
    "class BatchIndices(object):\n",
    "    def __init__(self, n, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = n,bs,shuffle\n",
    "        self.lock = threading.Lock()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.idxs = (np.random.permutation(self.n) \n",
    "                     if self.shuffle else np.arange(0, self.n))\n",
    "        self.curr = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            if self.curr >= self.n: self.reset()\n",
    "            ni = min(self.bs, self.n-self.curr)\n",
    "            res = self.idxs[self.curr:self.curr+ni]\n",
    "            self.curr += ni\n",
    "            return res\n",
    "        \n",
    "# segmentation generator\n",
    "class segm_generator(object):\n",
    "    def __init__(self, x, y, bs=64, out_sz=(224,224), train=True):\n",
    "        self.x, self.y, self.bs, self.train = x,y,bs,train\n",
    "        self.n, self.ri, self.ci, _ = x.shape\n",
    "        self.idx_gen = BatchIndices(self.n, bs, train)\n",
    "        self.ro, self.co = out_sz\n",
    "        self.ych = self.y.shape[-1] if len(y.shape)==4 else 1\n",
    "\n",
    "    def get_slice(self, i,o):\n",
    "        start = random.randint(0, i-o) if self.train else (i-o)\n",
    "        return slice(start, start+o)\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        slice_r = self.get_slice(self.ri, self.ro)\n",
    "        slice_c = self.get_slice(self.ci, self.co)\n",
    "        x = self.x[idx, slice_r, slice_c]\n",
    "        y = self.y[idx, slice_r, slice_c]\n",
    "        if self.train and (random.random()>0.5): \n",
    "            y = y[:,::-1]\n",
    "            x = x[:,::-1]\n",
    "        return x, y\n",
    "\n",
    "    def __next__(self):\n",
    "        idxs = next(self.idx_gen)\n",
    "        items = (self.get_item(idx) for idx in idxs)\n",
    "        xs,ys = zip(*items)\n",
    "        return np.stack(xs), np.stack(ys).reshape(len(ys), -1, self.ych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label name and lavel color codes\n",
    "label_names = ['Sky', 'Building', 'Pole', \n",
    "               'Road', 'Pavement', 'Tree', \n",
    "               'SignSymbol', 'Fence', 'Car', \n",
    "               'Pedestrian', 'Bicyclist', 'Unlabelled']\n",
    "\n",
    "label_codes = [(128,128,128),\n",
    "               (128,0,0),\n",
    "               (192,192,128),\n",
    "               (128,64,128),\n",
    "               (60,40,222),\n",
    "               (128,128,0),\n",
    "               (192,128,128),\n",
    "               (64,64,128),\n",
    "               (64,0,128),\n",
    "               (64,64,0),\n",
    "               (0,128,192),\n",
    "               (0,128,192)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert id label to color label\n",
    "def color_label(a): \n",
    "    r,c=a.shape\n",
    "    res = np.zeros((r,c,3), 'uint8')\n",
    "    for j in range(r): \n",
    "        for k in range(c):\n",
    "            o=label_codes[a[j,k]]\n",
    "            res[j,k] = o\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for trn(training images) and trn_labels(training 'id' labels)\n",
    "trn = imgs\n",
    "trn_labels = labels\n",
    "\n",
    "# Prepare for test(test images) and test_labels(test 'id' labels)\n",
    "test = test_imgs\n",
    "test_labels = test_labels\n",
    "\n",
    "# number of training and test images\n",
    "rnd_trn = len(trn_labels)\n",
    "rnd_test = len(test_labels)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Tiramisu network\n",
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "#def bn(x): return BatchNormalization(mode=2, axis=-1)(x)\n",
    "def bn(x): return x\n",
    "def relu_bn(x): return relu(bn(x))\n",
    "def concat(xs): return merge(xs, mode='concat', concat_axis=-1)\n",
    "\n",
    "def conv(x, nf, sz, wd, p, stride=1): \n",
    "    x = Convolution2D(nf, sz, sz, init='he_uniform', border_mode='same', \n",
    "                      subsample=(stride,stride), W_regularizer=l2(wd))(x)\n",
    "    return dropout(x, p)\n",
    "\n",
    "def conv_relu_bn(x, nf, sz=3, wd=0, p=0, stride=1): \n",
    "    return conv(relu_bn(x), nf, sz, wd=wd, p=p, stride=stride)\n",
    "\n",
    "def dense_block(n,x,growth_rate,p,wd):\n",
    "    added = []\n",
    "    for i in range(n):\n",
    "        b = conv_relu_bn(x, growth_rate, p=p, wd=wd)\n",
    "        x = concat([x, b])\n",
    "        added.append(b)\n",
    "    return x,added\n",
    "\n",
    "def transition_dn(x, p, wd):\n",
    "#     x = conv_relu_bn(x, x.get_shape().as_list()[-1], sz=1, p=p, wd=wd)\n",
    "#     return MaxPooling2D(strides=(2, 2))(x)\n",
    "    return conv_relu_bn(x, x.get_shape().as_list()[-1], sz=1, p=p, wd=wd, stride=2)\n",
    "\n",
    "def down_path(x, nb_layers, growth_rate, p, wd):\n",
    "    skips = []\n",
    "    for i,n in enumerate(nb_layers):\n",
    "        x,added = dense_block(n,x,growth_rate,p,wd)\n",
    "        skips.append(x)\n",
    "        x = transition_dn(x, p=p, wd=wd)\n",
    "    return skips, added\n",
    "\n",
    "def transition_up(added, wd=0):\n",
    "    x = concat(added)\n",
    "    _,r,c,ch = x.get_shape().as_list()\n",
    "    return Deconvolution2D(ch, 3, 3, (None,r*2,c*2,ch), init='he_uniform', \n",
    "               border_mode='same', subsample=(2,2), W_regularizer=l2(wd))(x)\n",
    "#     x = UpSampling2D()(x)\n",
    "#     return conv(x, ch, 2, wd, 0)\n",
    "\n",
    "def up_path(added, skips, nb_layers, growth_rate, p, wd):\n",
    "    for i,n in enumerate(nb_layers):\n",
    "        x = transition_up(added, wd)\n",
    "        x = concat([x,skips[i]])\n",
    "        x,added = dense_block(n,x,growth_rate,p,wd)\n",
    "    return x\n",
    "\n",
    "## Build the tiramisu model\n",
    "def reverse(a): return list(reversed(a))\n",
    "\n",
    "def create_tiramisu(nb_classes, img_input, nb_dense_block=6, \n",
    "    growth_rate=16, nb_filter=48, nb_layers_per_block=5, p=None, wd=0):\n",
    "    \n",
    "    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n",
    "        nb_layers = list(nb_layers_per_block)\n",
    "    else: nb_layers = [nb_layers_per_block] * nb_dense_block\n",
    "\n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    skips,added = down_path(x, nb_layers, growth_rate, p, wd)\n",
    "    x = up_path(added, reverse(skips[:-1]), reverse(nb_layers[:-1]), growth_rate, p, wd)\n",
    "    \n",
    "    x = conv(x, nb_classes, 1, wd, 0)\n",
    "    _,r,c,f = x.get_shape().as_list()\n",
    "    x = Reshape((-1, nb_classes))(x)\n",
    "    return Activation('softmax')(x)\n",
    "\n",
    "## Train the network\n",
    "limit_mem()\n",
    "input_shape = (224,224,3)\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "x = create_tiramisu(12, img_input, nb_layers_per_block=[4,5,7,10,12,15], p=0.2, wd=1e-4)\n",
    "\n",
    "model = Model(img_input, x)\n",
    "gen = segm_generator(trn, trn_labels, 3, train=True)\n",
    "gen_test = segm_generator(test, test_labels, 3, train=False)\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.RMSprop(1e-3), metrics=[\"accuracy\"])\n",
    "model.optimizer=keras.optimizers.RMSprop(1e-3, decay=1-0.99995)\n",
    "#model.optimizer=keras.optimizers.RMSprop(1e-3)\n",
    "K.set_value(model.optimizer.lr, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# start the training process\n",
    "model.fit_generator(gen, rnd_trn, 100, verbose=2, \n",
    "                    validation_data=gen_test, nb_val_samples=rnd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save network weights\n",
    "model.save_weights(PATH+'results/tiramisu_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with regularization \n",
    "lrg_sz = (352,480)\n",
    "gen = segm_generator(trn, trn_labels, 2, out_sz=lrg_sz, train=True)\n",
    "gen_test = segm_generator(test, test_labels, 2, out_sz=lrg_sz, train=False)\n",
    "\n",
    "lrg_shape = lrg_sz+(3,)\n",
    "lrg_input = Input(shape=lrg_shape)\n",
    "\n",
    "x = create_tiramisu(12, lrg_input, nb_layers_per_block=[4,5,7,10,12,15], p=0.2, wd=1e-4)\n",
    "lrg_model = Model(lrg_input, x)\n",
    "lrg_model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.RMSprop(1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load previous tiramisu\n",
    "lrg_model.load_weights(PATH+'results/tiramisu_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.fit_generator(gen, rnd_trn, 100, verbose=2, \n",
    "                    validation_data=gen_test, nb_val_samples=rnd_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
